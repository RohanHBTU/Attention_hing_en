{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"anuvaad.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# installing tensorflow_text \n!pip install tensorflow_text  ","metadata":{"id":"DGFTkuRvzWqc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cd555ad-f28d-40fc-8931-effd87043ffd","execution":{"iopub.status.busy":"2023-03-08T18:04:43.133140Z","iopub.execute_input":"2023-03-08T18:04:43.133878Z","iopub.status.idle":"2023-03-08T18:04:52.878904Z","shell.execute_reply.started":"2023-03-08T18:04:43.133837Z","shell.execute_reply":"2023-03-08T18:04:52.877654Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow_text in /opt/conda/lib/python3.7/site-packages (2.11.0)\nRequirement already satisfied: tensorflow<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow_text) (2.11.0)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow_text) (0.12.0)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.8.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (23.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.4.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.2.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (59.8.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.29.0)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (23.1.21)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.16.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (15.0.6.1)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.28.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.35.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.2.3)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.11.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.11.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# importing required libraries\nimport numpy as np\n\nimport typing\nfrom typing import Any, Tuple\n\nimport tensorflow as tf\n\nimport tensorflow_text as tf_text\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker","metadata":{"id":"tnxXKDjq3jEL","execution":{"iopub.status.busy":"2023-03-08T18:04:52.881858Z","iopub.execute_input":"2023-03-08T18:04:52.882631Z","iopub.status.idle":"2023-03-08T18:04:55.881139Z","shell.execute_reply.started":"2023-03-08T18:04:52.882576Z","shell.execute_reply":"2023-03-08T18:04:55.880016Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# using builtin implementations\nuse_builtins = True","metadata":{"id":"KPJ9J7iPUchc","execution":{"iopub.status.busy":"2023-03-08T18:04:55.882895Z","iopub.execute_input":"2023-03-08T18:04:55.883689Z","iopub.status.idle":"2023-03-08T18:04:55.888423Z","shell.execute_reply.started":"2023-03-08T18:04:55.883650Z","shell.execute_reply":"2023-03-08T18:04:55.887336Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#@title Shape checker\nclass ShapeChecker():\n  def __init__(self):\n    # Keep a cache of every axis-name seen\n    self.shapes = {}\n\n  def __call__(self, tensor, names, broadcast=False):\n    if not tf.executing_eagerly():\n      return\n\n    if isinstance(names, str):\n      names = (names,)\n\n    shape = tf.shape(tensor)\n    rank = tf.rank(tensor)\n\n    if rank != len(names):\n      raise ValueError(f'Rank mismatch:\\n'\n                       f'    found {rank}: {shape.numpy()}\\n'\n                       f'    expected {len(names)}: {names}\\n')\n\n    for i, name in enumerate(names):\n      if isinstance(name, int):\n        old_dim = name\n      else:\n        old_dim = self.shapes.get(name, None)\n      new_dim = shape[i]\n\n      if (broadcast and new_dim == 1):\n        continue\n\n      if old_dim is None:\n        # If the axis name is new, add its length to the cache.\n        self.shapes[name] = new_dim\n        continue\n\n      if new_dim != old_dim:\n        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n                         f\"    found: {new_dim}\\n\"\n                         f\"    expected: {old_dim}\\n\")","metadata":{"id":"KqFqKi4fqN9X","execution":{"iopub.status.busy":"2023-03-08T18:04:55.891505Z","iopub.execute_input":"2023-03-08T18:04:55.892199Z","iopub.status.idle":"2023-03-08T18:04:55.902986Z","shell.execute_reply.started":"2023-03-08T18:04:55.892161Z","shell.execute_reply":"2023-03-08T18:04:55.901928Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install Metaphone\nfrom metaphone import doublemetaphone\nimport pandas as pd\nimport re\ndata=pd.read_csv(\"/kaggle/input/file-name/file_name.csv\")\n\ndata['tr']=data['tr'].apply(lambda x: str(x).lower())\ndata['Sentence']=data['Sentence'].apply(lambda x: str(x).lower())","metadata":{"id":"rOduTbljY-4e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b95ed0e1-fb62-464b-f0a4-738b6ffc11a2","execution":{"iopub.status.busy":"2023-03-08T18:14:16.250708Z","iopub.execute_input":"2023-03-08T18:14:16.251218Z","iopub.status.idle":"2023-03-08T18:14:26.329325Z","shell.execute_reply.started":"2023-03-08T18:14:16.251179Z","shell.execute_reply":"2023-03-08T18:14:26.327923Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: Metaphone in /opt/conda/lib/python3.7/site-packages (0.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"hin_vocab=dict()\nfor i in data['Sentence'].apply(lambda x: re.sub(\"[.!?\\\\-\\'\\\"]\", \"\", x)):\n    for j in i.split(' '):\n        hin_vocab[doublemetaphone(j)[0]+'*'+doublemetaphone(j[::-1])[0]+'*'+j[:2]+'*'+j[len(j)-1:]]=j\nfor i in hin_vocab:\n    a=set()\n    a.add(hin_vocab[i])\n    hin_vocab[i]=a\nfor i in data['Sentence'].apply(lambda x: re.sub(\"[.!?\\\\-\\'\\\"]\", \"\", x)):\n    for j in i.split(' '):\n        hin_vocab[doublemetaphone(j)[0]+'*'+doublemetaphone(j[::-1])[0]+'*'+j[:2]+'*'+j[len(j)-1:]].add(j)\nprint(len(hin_vocab))\n#hin_vocab","metadata":{"execution":{"iopub.status.busy":"2023-03-08T18:14:26.332517Z","iopub.execute_input":"2023-03-08T18:14:26.333402Z","iopub.status.idle":"2023-03-08T18:14:34.836413Z","shell.execute_reply.started":"2023-03-08T18:14:26.333356Z","shell.execute_reply":"2023-03-08T18:14:34.835177Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"17325\n","output_type":"stream"}]},{"cell_type":"code","source":"data['Sentence']=data['Sentence'].apply(lambda x: re.sub(\"[.!?\\\\-\\'\\\"]\", \"\", x))\ndata['Sentence']","metadata":{"execution":{"iopub.status.busy":"2023-03-08T18:14:34.837825Z","iopub.execute_input":"2023-03-08T18:14:34.838360Z","iopub.status.idle":"2023-03-08T18:14:34.878190Z","shell.execute_reply.started":"2023-03-08T18:14:34.838318Z","shell.execute_reply":"2023-03-08T18:14:34.877238Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0        congratulations on you celebrating british kid...\n1        uske liye toh bahot kuch karna padega ye pappi...\n2        yehi to hum semjhane ki koshish kar rahe hain ...\n3                                           cake kaha hai \n4        im in hawaii at the moment  home next friday n...\n                               ...                        \n13733    dr kumar vishwas: koi deewana kehta hai koi pa...\n13734    me: aaj kuch toofani karte haimom: pani ki bot...\n13735    pyar mangi to jaan dengi,milk mango to kher de...\n13736                      kaale kaale baal gaal gore gore\n13737                              ye sab auntyon ke saath\nName: Sentence, Length: 13738, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"def change_vocab(line):\n    string=''\n    for j in line.split(' '):\n        string=string+list(hin_vocab[doublemetaphone(j)[0]+'*'+doublemetaphone(j[::-1])[0]+'*'+j[:2]+'*'+j[len(j)-1:]])[0]+' '\n    return string","metadata":{"execution":{"iopub.status.busy":"2023-03-08T18:14:34.880814Z","iopub.execute_input":"2023-03-08T18:14:34.881591Z","iopub.status.idle":"2023-03-08T18:14:34.888266Z","shell.execute_reply.started":"2023-03-08T18:14:34.881552Z","shell.execute_reply":"2023-03-08T18:14:34.887206Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data['Sentence']=data['Sentence'].apply(lambda x: change_vocab(x).strip())","metadata":{"execution":{"iopub.status.busy":"2023-03-08T18:14:34.889657Z","iopub.execute_input":"2023-03-08T18:14:34.890130Z","iopub.status.idle":"2023-03-08T18:14:39.212160Z","shell.execute_reply.started":"2023-03-08T18:14:34.890092Z","shell.execute_reply":"2023-03-08T18:14:39.211088Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-03-08T18:14:39.213476Z","iopub.execute_input":"2023-03-08T18:14:39.213832Z","iopub.status.idle":"2023-03-08T18:14:39.228226Z","shell.execute_reply.started":"2023-03-08T18:14:39.213795Z","shell.execute_reply":"2023-03-08T18:14:39.226938Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                Sentence  \\\n0      congratulations on youuuuu celebrating british...   \n1      uske lie toh bahut kucch karwana padhiyega yee...   \n2      yehi tooo hum semjhane kii koshishh kaur rahiy...   \n3      cake kahaa haiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii   \n4      im inn haiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii ...   \n...                                                  ...   \n13733  dr kumar vishwas: koii deewana kehta haiiiiiii...   \n13734  me: aawaj kucch toofani karode haimom: pani ki...   \n13735  pyaar maangi tooo jaon dengi,milk mango tooo k...   \n13736                     kalwe kalwe bal gaal gore gore   \n13737                          yee saab auntyon kee sath   \n\n                                     English_Translation  \\\n0      @some users congratulate you for celebrating B...   \n1      @Lokardi_ rat we should a lot more for that, b...   \n2      @Slimswami ehi, this is what i'm expecting you...   \n3             @Where is Dramebajakudi where is the cake?   \n4      @some user Don't want to come home next friday...   \n...                                                  ...   \n13733  Dr Kumar Vishwas: \"Some used to say lover.. So...   \n13734  Me: Let's do some stormy today.\\n\\nMom: Fill t...   \n13735  Ask for love we'll give life, ask for milk we'...   \n13736  @imcomplicated__black black hair cheeks fair fair   \n13737                             All this with aunties?   \n\n                                                      tr  \n0      congratulations on you celebrating british kid...  \n1      you will have to do a lot for that, it will no...  \n2      this is what we are trying to understand. peop...  \n3                                    where is the cake??  \n4      i'm in hawaii at the moment . home next friday...  \n...                                                  ...  \n13733  dr. kumar vishwas: \"some say crazy..some think...  \n13734  me: let's do something stormy today. mother: f...  \n13735  if you ask for love, you will give your life, ...  \n13736                        kale kale bal gal gore gore  \n13737                         all this with the aunties?  \n\n[13738 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>English_Translation</th>\n      <th>tr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>congratulations on youuuuu celebrating british...</td>\n      <td>@some users congratulate you for celebrating B...</td>\n      <td>congratulations on you celebrating british kid...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>uske lie toh bahut kucch karwana padhiyega yee...</td>\n      <td>@Lokardi_ rat we should a lot more for that, b...</td>\n      <td>you will have to do a lot for that, it will no...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>yehi tooo hum semjhane kii koshishh kaur rahiy...</td>\n      <td>@Slimswami ehi, this is what i'm expecting you...</td>\n      <td>this is what we are trying to understand. peop...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cake kahaa haiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii</td>\n      <td>@Where is Dramebajakudi where is the cake?</td>\n      <td>where is the cake??</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im inn haiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii ...</td>\n      <td>@some user Don't want to come home next friday...</td>\n      <td>i'm in hawaii at the moment . home next friday...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13733</th>\n      <td>dr kumar vishwas: koii deewana kehta haiiiiiii...</td>\n      <td>Dr Kumar Vishwas: \"Some used to say lover.. So...</td>\n      <td>dr. kumar vishwas: \"some say crazy..some think...</td>\n    </tr>\n    <tr>\n      <th>13734</th>\n      <td>me: aawaj kucch toofani karode haimom: pani ki...</td>\n      <td>Me: Let's do some stormy today.\\n\\nMom: Fill t...</td>\n      <td>me: let's do something stormy today. mother: f...</td>\n    </tr>\n    <tr>\n      <th>13735</th>\n      <td>pyaar maangi tooo jaon dengi,milk mango tooo k...</td>\n      <td>Ask for love we'll give life, ask for milk we'...</td>\n      <td>if you ask for love, you will give your life, ...</td>\n    </tr>\n    <tr>\n      <th>13736</th>\n      <td>kalwe kalwe bal gaal gore gore</td>\n      <td>@imcomplicated__black black hair cheeks fair fair</td>\n      <td>kale kale bal gal gore gore</td>\n    </tr>\n    <tr>\n      <th>13737</th>\n      <td>yee saab auntyon kee sath</td>\n      <td>All this with aunties?</td>\n      <td>all this with the aunties?</td>\n    </tr>\n  </tbody>\n</table>\n<p>13738 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['len_sen']=data['Sentence'].apply(lambda x: len(x.split(' ')))\ndata=data[data['len_sen']<=20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp=list(data['Sentence'])\ntarg=list(data['tr'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# printing last english sentence\nprint(targ[-1])","metadata":{"id":"lH_dPY8TRp3c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4486ac6-bd0f-4b6f-c685-5bdf1983e769","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# printing first 100 english sentence\nprint(targ[:100])","metadata":{"id":"WtYLR0ZWXDld","colab":{"base_uri":"https://localhost:8080/"},"outputId":"afcfed6b-ee0f-4007-9b3d-9cafc3eac537","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# printing first 100 hinglish sentences\nprint(inp[-1:])","metadata":{"id":"WdC25G6AZXr9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26bc2c3e-c413-4715-f08a-65b5ad1ba001","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# arrays of strings are shuffled and batches are made\nBUFFER_SIZE = len(inp)\nBATCH_SIZE = 64\n\ndataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE)","metadata":{"id":"TqHsArVZ3jFS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for example_input_batch, example_target_batch in dataset.take(1):\n  print(example_input_batch[:5])\n  print()\n  print(example_target_batch[:5])\n  break","metadata":{"id":"qc6-NK1GtWQt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4059f9ad-4d6e-4204-d40a-840261b82f90","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unicode normalization operation - first step to standardize data\nexample_text = tf.constant('Yahi haal hai')\n\nprint(example_text.numpy())\nprint(tf_text.normalize_utf8(example_text, 'NFKD').numpy())","metadata":{"id":"mD0e-DWGQ2Vo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"52e95336-e962-4e89-da30-956c44458493","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tf_lower_and_split_punct(text):\n  # Split accecented characters.\n  text = tf_text.normalize_utf8(text, 'NFKD')\n  text = tf.strings.lower(text)\n  # Keep space, a to z, and select punctuation.\n  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n  # Add spaces around punctuation.\n  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n  # Strip whitespace.\n  text = tf.strings.strip(text)\n\n  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n  return text","metadata":{"id":"chTF5N885F0P","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(example_text.numpy().decode())\nprint(tf_lower_and_split_punct(example_text).numpy().decode())","metadata":{"id":"UREvDg3sEKYa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0abfd72-ff76-4661-809c-d1b40f6debb8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_vocab_size = 5000\n\ninput_text_processor = tf.keras.layers.TextVectorization(    # handles vocabulary extraction & conversion of i/p text to sequences of tokens\n    standardize=tf_lower_and_split_punct,\n    max_tokens=max_vocab_size)","metadata":{"id":"eAY9k49G3jE_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text_processor.adapt(inp)    # initializes the layer based on the data\n\n# Here are the first 10 words from the vocabulary:\ninput_text_processor.get_vocabulary()[:10]\n# Hinglish TextVectorization layer","metadata":{"id":"bmsI1Yql8FYe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89009883-0834-449f-d408-0d947cd033b2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_text_processor = tf.keras.layers.TextVectorization(\n    standardize=tf_lower_and_split_punct,\n    max_tokens=max_vocab_size)\n\noutput_text_processor.adapt(targ)\noutput_text_processor.get_vocabulary()[:10]\n# English TextVectorization layer","metadata":{"id":"jlC4xuZnKLBS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b307cdd-52db-48bf-f9bc-2510dd84bd19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the above layers convert a batch of strings into a batch of token IDs\nexample_tokens = input_text_processor(example_input_batch)\nexample_tokens[:3, :10]","metadata":{"id":"9KZxj8IrNZ9S","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed7ca51e-cd13-4c35-dd4e-fd706b1fb34a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_vocabulary - converts token IDs back to text\ninput_vocab = np.array(input_text_processor.get_vocabulary())\ntokens = input_vocab[example_tokens[0].numpy()]\n' '.join(tokens)","metadata":{"id":"98g9rcxGQY0I","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"43515fd5-6811-41ec-d9e9-8e1c4d920d81","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# token IDs converted into a mask\nplt.subplot(1, 2, 1)\nplt.pcolormesh(example_tokens)\nplt.title('Token IDs')\n\nplt.subplot(1, 2, 2)\nplt.pcolormesh(example_tokens != 0)\nplt.title('Mask')","metadata":{"id":"_jx4Or_eFRSz","colab":{"base_uri":"https://localhost:8080/","height":298},"outputId":"fd68e833-9404-407b-a54b-333bb35ffd2b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining constants for the model\nembedding_dim = 256\nunits = 1024","metadata":{"id":"_a9uNz3-IrF-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoding","metadata":{"id":"6tQ8xnOH7mFc"}},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n    super(Encoder, self).__init__()\n    self.enc_units = enc_units\n    self.input_vocab_size = input_vocab_size\n\n    # The embedding layer converts tokens to vectors\n    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n                                               embedding_dim)\n\n    # The GRU RNN layer processes those vectors sequentially.\n    self.gru = tf.keras.layers.GRU(self.enc_units,\n                                   # Return the sequence and state\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform',\n                                  recurrent_dropout=0.3)\n\n  def call(self, tokens, state=None):\n    shape_checker = ShapeChecker()\n    shape_checker(tokens, ('batch', 's'))\n\n    # 2. The embedding layer looks up the embedding for each token.\n    vectors = self.embedding(tokens)\n    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n\n    # 3. The GRU processes the embedding sequence.\n    #    output shape: (batch, s, enc_units)\n    #    state shape: (batch, enc_units)\n    output, state = self.gru(vectors, initial_state=state)\n    shape_checker(output, ('batch', 's', 'enc_units'))\n    shape_checker(state, ('batch', 'enc_units'))\n\n    # 4. Returns the new sequence and its state.\n    return output, state","metadata":{"id":"nZ2rI24i3jFg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the input text to tokens.\nexample_tokens = input_text_processor(example_input_batch)\n\n# Encode the input sequence.\nencoder = Encoder(input_text_processor.vocabulary_size(),\n                  embedding_dim, units)\nexample_enc_output, example_enc_state = encoder(example_tokens)\n\nprint(f'Input batch, shape (batch): {example_input_batch.shape}')\nprint(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\nprint(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\nprint(f'Encoder state, shape (batch, units): {example_enc_state.shape}')","metadata":{"id":"60gSVh05Jl6l","colab":{"base_uri":"https://localhost:8080/"},"outputId":"99c5ac95-5e34-4591-e00a-16b2d068052d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Attention layer","metadata":{"id":"mI7Zgyrp89GK"}},{"cell_type":"code","source":"class BahdanauAttention(tf.keras.layers.Layer):\n  def __init__(self, units):\n    super().__init__()\n    # For Eqn. (4), the  Bahdanau attention\n    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n\n    self.attention = tf.keras.layers.AdditiveAttention()\n\n  def call(self, query, value, mask):\n    shape_checker = ShapeChecker()\n    shape_checker(query, ('batch', 't', 'query_units'))\n    shape_checker(value, ('batch', 's', 'value_units'))\n    shape_checker(mask, ('batch', 's'))\n\n    # From Eqn. (4), `W1@ht`.\n    w1_query = self.W1(query)\n    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n\n    # From Eqn. (4), `W2@hs`.\n    w2_key = self.W2(value)\n    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n\n    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n    value_mask = mask\n\n    context_vector, attention_weights = self.attention(\n        inputs = [w1_query, value, w2_key],\n        mask=[query_mask, value_mask],\n        return_attention_scores = True,\n    )\n    shape_checker(context_vector, ('batch', 't', 'value_units'))\n    shape_checker(attention_weights, ('batch', 't', 's'))\n\n    return context_vector, attention_weights","metadata":{"id":"momiE59lXo6U","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating BahdanauAttention layer\nattention_layer = BahdanauAttention(units)","metadata":{"id":"t4QMlOp8Gidh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(example_tokens != 0).shape","metadata":{"id":"DYSHqmORgVFo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8feaa6f2-f454-4fa6-bf69-29762aacebee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Later, the decoder will generate this attention query\nexample_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n\n# Attend to the encoded tokens\n\ncontext_vector, attention_weights = attention_layer(\n    query=example_attention_query,\n    value=example_enc_output,\n    mask=(example_tokens != 0))\n\nprint(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\nprint(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')","metadata":{"id":"7y7hjPkNMmHh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"600899f2-e9d6-467a-ba4a-04ab287d4f08","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(1, 2, 1)\nplt.pcolormesh(attention_weights[:, 0, :])\nplt.title('Attention weights')\n\nplt.subplot(1, 2, 2)\nplt.pcolormesh(example_tokens != 0)\nplt.title('Mask')\n","metadata":{"id":"Rqr8XGsAJlf6","colab":{"base_uri":"https://localhost:8080/","height":298},"outputId":"a8f59ec0-d2a6-49a2-de95-aa80d7f7a7b7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention_weights.shape","metadata":{"id":"ZuzrCdmYlTcJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8dfa3d00-cd0c-48e8-8718-af89ed82d106","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention_slice = attention_weights[0, 0].numpy()\nattention_slice = attention_slice[attention_slice != 0]","metadata":{"id":"qIMwC-f-ZC8N","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title\nplt.suptitle('Attention weights for one sequence')\n\nplt.figure(figsize=(12, 6))\na1 = plt.subplot(1, 2, 1)\nplt.bar(range(len(attention_slice)), attention_slice)\n# freeze the xlim\nplt.xlim(plt.xlim())\nplt.xlabel('Attention weights')\n\na2 = plt.subplot(1, 2, 2)\nplt.bar(range(len(attention_slice)), attention_slice)\nplt.xlabel('Attention weights, zoomed')\n\n# zoom in\ntop = max(a1.get_ylim())\nzoom = 0.85*top\na2.set_ylim([0.90*top, top])\na1.plot(a1.get_xlim(), [zoom, zoom], color='k')","metadata":{"id":"ysWDPO6hOS8X","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"9f941203-0962-4219-98cb-efdfe46a5faa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decoder","metadata":{"id":"g68xf3c_-gBS"}},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n    super(Decoder, self).__init__()\n    self.dec_units = dec_units\n    self.output_vocab_size = output_vocab_size\n    self.embedding_dim = embedding_dim\n\n    # For Step 1. The embedding layer converts token IDs to vectors\n    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n                                               embedding_dim)\n\n    # For Step 2. The RNN keeps track of what's been generated so far.\n    self.gru = tf.keras.layers.GRU(self.dec_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform',\n                                  recurrent_dropout=0.3)\n\n    # For step 3. The RNN output will be the query for the attention layer.\n    self.attention = BahdanauAttention(self.dec_units)\n\n    # For step 4. Eqn. (3): converting `ct` to `at`\n    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n                                    use_bias=False)\n\n    # For step 5. This fully connected layer produces the logits for each output token.\n    self.fc = tf.keras.layers.Dense(self.output_vocab_size)","metadata":{"id":"erYvHIgAl8kh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecoderInput(typing.NamedTuple):\n  new_tokens: Any\n  enc_output: Any\n  mask: Any\n\nclass DecoderOutput(typing.NamedTuple):\n  logits: Any\n  attention_weights: Any","metadata":{"id":"7WfSIb2sArRT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def call(self,\n         inputs: DecoderInput,\n         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n  shape_checker = ShapeChecker()\n  shape_checker(inputs.new_tokens, ('batch', 't'))\n  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n  shape_checker(inputs.mask, ('batch', 's'))\n\n  if state is not None:\n    shape_checker(state, ('batch', 'dec_units'))\n\n  # Step 1. Lookup the embeddings\n  vectors = self.embedding(inputs.new_tokens)\n  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n\n  # Step 2. Process one step with the RNN\n  rnn_output, state = self.gru(vectors, initial_state=state)\n\n  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n  shape_checker(state, ('batch', 'dec_units'))\n\n  # Step 3. Use the RNN output as the query for the attention over the\n  # encoder output.\n  context_vector, attention_weights = self.attention(\n      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n  shape_checker(attention_weights, ('batch', 't', 's'))\n\n  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n  #     [ct; ht] shape: (batch t, value_units + query_units)\n  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n\n  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n  attention_vector = self.Wc(context_and_rnn_output)\n  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n\n  # Step 5. Generate logit predictions:\n  logits = self.fc(attention_vector)\n  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n\n  return DecoderOutput(logits, attention_weights), state","metadata":{"id":"PJOi5btHAPNK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Decoder.call = call","metadata":{"id":"Ay_mTMPfnb2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(output_text_processor.vocabulary_size(),\n                  embedding_dim, units)","metadata":{"id":"4ZUMbYXIEVeA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the target sequence, and collect the \"[START]\" tokens\nexample_output_tokens = output_text_processor(example_target_batch)\n\nstart_index = output_text_processor.get_vocabulary().index('[START]')\nfirst_token = tf.constant([[start_index]] * example_output_tokens.shape[0])","metadata":{"id":"4u6eJBU4GL40","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the decoder\ndec_result, dec_state = decoder(\n    inputs = DecoderInput(new_tokens=first_token,\n                          enc_output=example_enc_output,\n                          mask=(example_tokens != 0)),\n    state = example_enc_state\n)\n\nprint(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\nprint(f'state shape: (batch_size, dec_units) {dec_state.shape}')","metadata":{"id":"E5hqvbR5FUCD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec292583-153d-4d60-d79e-082f2ed7a208","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample token according to logits\nsampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)","metadata":{"id":"P5UY8wko3jFp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decode the token as first word of o/p\nvocab = np.array(output_text_processor.get_vocabulary())\nfirst_word = vocab[sampled_token.numpy()]\nfirst_word[:5]","metadata":{"id":"lKXTLYu4IV7I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c243ce7-23fc-4781-98c6-9d64e07e13d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decoder generates second set of logits\ndec_result, dec_state = decoder(\n    DecoderInput(sampled_token,\n                 example_enc_output,\n                 mask=(example_tokens != 0)),\n    state=dec_state)","metadata":{"id":"pX1VF9XDJTOM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\nfirst_word = vocab[sampled_token.numpy()]\nfirst_word[:5]","metadata":{"id":"H1rs0XL7Y2aS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44ae682c-c8c3-45e6-9f2b-e56c89f3a46a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training","metadata":{"id":"hQpRXZdxBYAO"}},{"cell_type":"code","source":"# Loss function definition\nclass MaskedLoss(tf.keras.losses.Loss):\n  def __init__(self):\n    self.name = 'masked_loss'\n    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True, reduction='none')\n\n  def __call__(self, y_true, y_pred):\n    shape_checker = ShapeChecker()\n    shape_checker(y_true, ('batch', 't'))\n    shape_checker(y_pred, ('batch', 't', 'logits'))\n\n    # Calculate the loss for each item in the batch.\n    loss = self.loss(y_true, y_pred)\n    shape_checker(loss, ('batch', 't'))\n\n    # Mask off the losses on padding.\n    mask = tf.cast(y_true != 0, tf.float32)\n    shape_checker(mask, ('batch', 't'))\n    loss *= mask\n\n    # Return the total.\n    return tf.reduce_sum(loss)","metadata":{"id":"WmTHr5iV3jFr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# implementing training step\nclass TrainTranslator(tf.keras.Model):\n  def __init__(self, embedding_dim, units,\n               input_text_processor,\n               output_text_processor, \n               use_tf_function=True):\n    super().__init__()\n    # Build the encoder and decoder\n    encoder = Encoder(input_text_processor.vocabulary_size(),\n                      embedding_dim, units)\n    decoder = Decoder(output_text_processor.vocabulary_size(),\n                      embedding_dim, units)\n\n    self.encoder = encoder\n    self.decoder = decoder\n    self.input_text_processor = input_text_processor\n    self.output_text_processor = output_text_processor\n    self.use_tf_function = use_tf_function\n    self.shape_checker = ShapeChecker()\n\n  def train_step(self, inputs):\n    self.shape_checker = ShapeChecker()\n    if self.use_tf_function:\n      return self._tf_train_step(inputs)\n    else:\n      return self._train_step(inputs)","metadata":{"id":"WWIyuy71TkJT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Receiving batches of english & hinglish data\n# Converting those raw text inputs to token-embeddings and masks.\ndef _preprocess(self, input_text, target_text):\n  self.shape_checker(input_text, ('batch',))\n  self.shape_checker(target_text, ('batch',))\n\n  # Convert the text to token IDs\n  input_tokens = self.input_text_processor(input_text)\n  target_tokens = self.output_text_processor(target_text)\n  self.shape_checker(input_tokens, ('batch', 's'))\n  self.shape_checker(target_tokens, ('batch', 't'))\n\n  # Convert IDs to masks.\n  input_mask = input_tokens != 0\n  self.shape_checker(input_mask, ('batch', 's'))\n\n  target_mask = target_tokens != 0\n  self.shape_checker(target_mask, ('batch', 't'))\n\n  return input_tokens, input_mask, target_tokens, target_mask","metadata":{"id":"ZlYE68wzXoA8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainTranslator._preprocess = _preprocess","metadata":{"id":"lHy6hzStrgjQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\ndef _train_step(self, inputs):\n  input_text, target_text = inputs  \n\n  (input_tokens, input_mask,\n   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n\n  max_target_length = tf.shape(target_tokens)[1]\n\n  with tf.GradientTape() as tape:\n    # Encode the input\n    enc_output, enc_state = self.encoder(input_tokens)\n    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n    self.shape_checker(enc_state, ('batch', 'enc_units'))\n\n    # Initialize the decoder's state to the encoder's final state.\n    # This only works if the encoder and decoder have the same number of\n    # units.\n    dec_state = enc_state\n    loss = tf.constant(0.0)\n\n    for t in tf.range(max_target_length-1):\n      # Pass in two tokens from the target sequence:\n      # 1. The current input to the decoder.\n      # 2. The target for the decoder's next prediction.\n      new_tokens = target_tokens[:, t:t+2]\n      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n                                             enc_output, dec_state)\n      loss = loss + step_loss\n\n    # Average the loss over all non padding tokens.\n    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n\n  # Apply an optimization step\n  variables = self.trainable_variables \n  gradients = tape.gradient(average_loss, variables)\n  self.optimizer.apply_gradients(zip(gradients, variables))\n\n  # Return a dict mapping metric names to current value\n  return {'batch_loss': average_loss}","metadata":{"id":"Qs_gsISsYPpY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainTranslator._train_step = _train_step","metadata":{"id":"KGwWHIxLrjGR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# executes the decoder and calculates the incremental loss and new decoder state \ndef _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n\n  # Run the decoder one step.\n  decoder_input = DecoderInput(new_tokens=input_token,\n                               enc_output=enc_output,\n                               mask=input_mask)\n\n  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n  self.shape_checker(dec_state, ('batch', 'dec_units'))\n\n  # `self.loss` returns the total for non-padded tokens\n  y = target_token\n  y_pred = dec_result.logits\n  step_loss = self.loss(y, y_pred)\n\n  return step_loss, dec_state","metadata":{"id":"9VrzgwztXzYJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainTranslator._loop_step = _loop_step","metadata":{"id":"xj3I7VULrk1R","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing the training step\ntranslator = TrainTranslator(\n    embedding_dim, units,\n    input_text_processor=input_text_processor,\n    output_text_processor=output_text_processor,\n    use_tf_function=False)\n\n# Configure the loss and optimizer\ntranslator.compile(\n    optimizer=tf.optimizers.Adam(),\n    loss=MaskedLoss(),\n)","metadata":{"id":"OA6bCske8TXm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.log(output_text_processor.vocabulary_size())","metadata":{"id":"zHe-OudqCFGK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2fbae89-05d6-4eae-850b-804a97879845","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor n in range(10):\n  print(translator.train_step([example_input_batch, example_target_batch]))\nprint()","metadata":{"id":"VwMU9cFEfjha","colab":{"base_uri":"https://localhost:8080/"},"outputId":"55585974-6d03-477b-fa1b-c040e9bd7a30","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# maximizing performance while training\n@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\ndef _tf_train_step(self, inputs):\n  return self._train_step(inputs)","metadata":{"id":"UFUsTKQx0jaH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainTranslator._tf_train_step = _tf_train_step","metadata":{"id":"2-bgU59jrztQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translator.use_tf_function = True","metadata":{"id":"KC8bRv_Gr3H9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translator.train_step([example_input_batch, example_target_batch])","metadata":{"id":"pLQZsX2dp1QK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"db5ec937-a3e4-40b2-ec54-9dea9c4f3519","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor n in range(10):\n  print(translator.train_step([example_input_batch, example_target_batch]))\nprint()","metadata":{"id":"UzXXMwjXCqqh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c536483a-a0b5-4c1b-b99b-3cc35a2caf48","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = []\nfor n in range(100):\n  print('.', end='')\n  logs = translator.train_step([example_input_batch, example_target_batch])\n  losses.append(logs['batch_loss'].numpy())\n\nprint()\nplt.plot(losses)","metadata":{"id":"U-dIWMIBqK7b","colab":{"base_uri":"https://localhost:8080/","height":300},"outputId":"6df08356-994b-48fa-b64c-ebcdae2c6291","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building a fresh copy of the model to train from scratch since the training step is working\ntrain_translator = TrainTranslator(\n    embedding_dim, units,\n    input_text_processor=input_text_processor,\n    output_text_processor=output_text_processor)\n\n# Configure the loss and optimizer\ntrain_translator.compile(\n    optimizer=tf.optimizers.Adam(),\n    loss=MaskedLoss(),\n)","metadata":{"id":"Emgfgh4tAmJt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the model","metadata":{"id":"1h7Dmiy1De8S"}},{"cell_type":"code","source":"class BatchLogs(tf.keras.callbacks.Callback):\n  def __init__(self, key):\n    self.key = key\n    self.logs = []\n\n  def on_train_batch_end(self, n, logs):\n    self.logs.append(logs[self.key])\n\nbatch_loss = BatchLogs('batch_loss')","metadata":{"id":"J7m4mtnj80sq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_translator.fit(dataset, epochs=100,\n                     callbacks=[batch_loss])","metadata":{"id":"BQd_esVVoSf3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"06c29d9e-195b-46a6-a401-92eb33ccdc94","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(batch_loss.logs)\nplt.ylim([0, 50])\nplt.xlabel('Batch #')\nplt.ylabel('CE/token')","metadata":{"id":"38rLdlmtQHCm","colab":{"base_uri":"https://localhost:8080/","height":300},"outputId":"2c24e8f8-3ef3-4477-b845-34da28c8f96b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Translation","metadata":{"id":"ygvrNyB-DvUF"}},{"cell_type":"code","source":"class Translator(tf.Module):\n\n  def __init__(self, encoder, decoder, input_text_processor,\n               output_text_processor):\n    self.encoder = encoder\n    self.decoder = decoder\n    self.input_text_processor = input_text_processor\n    self.output_text_processor = output_text_processor\n\n    self.output_token_string_from_index = (\n        tf.keras.layers.StringLookup(\n            vocabulary=output_text_processor.get_vocabulary(),\n            mask_token='',\n            invert=True))\n\n    # The output should never generate padding, unknown, or start.\n    index_from_string = tf.keras.layers.StringLookup(\n        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n\n    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n    token_mask[np.array(token_mask_ids)] = True\n    self.token_mask = token_mask\n\n    self.start_token = index_from_string(tf.constant('[START]'))\n    self.end_token = index_from_string(tf.constant('[END]'))","metadata":{"id":"PO-CLL1LVBbM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translator = Translator(\n    encoder=train_translator.encoder,\n    decoder=train_translator.decoder,\n    input_text_processor=input_text_processor,\n    output_text_processor=output_text_processor,\n)","metadata":{"id":"iBQzFZ9uWU79","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting token IDs to human readable text\ndef tokens_to_text(self, result_tokens):\n  shape_checker = ShapeChecker()\n  shape_checker(result_tokens, ('batch', 't'))\n  result_text_tokens = self.output_token_string_from_index(result_tokens)\n  shape_checker(result_text_tokens, ('batch', 't'))\n\n  result_text = tf.strings.reduce_join(result_text_tokens,\n                                       axis=1, separator=' ')\n  shape_checker(result_text, ('batch'))\n\n  result_text = tf.strings.strip(result_text)\n  shape_checker(result_text, ('batch',))\n  return result_text","metadata":{"id":"8IjwKTwtmdFf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Translator.tokens_to_text = tokens_to_text","metadata":{"id":"912aV0K7r90w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inputting random token IDs to see what it generates\nexample_output_tokens = tf.random.uniform(\n    shape=[5, 2], minval=0, dtype=tf.int64,\n    maxval=output_text_processor.vocabulary_size())\ntranslator.tokens_to_text(example_output_tokens).numpy()","metadata":{"id":"cWCMHdoS32QN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b49a9c58-b11b-4aa3-e127-3a7b4f5b98d8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# takes the decoder's logit outputs and samples token IDs from that distribution\ndef sample(self, logits, temperature):\n  shape_checker = ShapeChecker()\n  # 't' is usually 1 here.\n  shape_checker(logits, ('batch', 't', 'vocab'))\n  shape_checker(self.token_mask, ('vocab',))\n\n  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n\n  # Set the logits for all masked tokens to -inf, so they are never chosen.\n  logits = tf.where(self.token_mask, -np.inf, logits)\n\n  if temperature == 0.0:\n    new_tokens = tf.argmax(logits, axis=-1)\n  else: \n    logits = tf.squeeze(logits, axis=1)\n    new_tokens = tf.random.categorical(logits/temperature,\n                                        num_samples=1)\n  \n  shape_checker(new_tokens, ('batch', 't'))\n\n  return new_tokens","metadata":{"id":"8lfuj3GcdD6e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Translator.sample = sample","metadata":{"id":"4DpDnBdBdL9_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing the function on random i/p\nexample_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\nexample_output_tokens = translator.sample(example_logits, temperature=1.0)\nexample_output_tokens","metadata":{"id":"rwLT0nxXym80","colab":{"base_uri":"https://localhost:8080/"},"outputId":"492baa1e-7a3f-4ee3-a0cb-4df725ece439","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# implementing text to text translation loop\ndef translate_unrolled(self,\n                       input_text, *,\n                       max_length=50,\n                       return_attention=True,\n                       temperature=1.0):\n  batch_size = tf.shape(input_text)[0]\n  input_tokens = self.input_text_processor(input_text)\n  enc_output, enc_state = self.encoder(input_tokens)\n\n  dec_state = enc_state\n  new_tokens = tf.fill([batch_size, 1], self.start_token)\n\n  result_tokens = []\n  attention = []\n  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n\n  for _ in range(max_length):\n    dec_input = DecoderInput(new_tokens=new_tokens,\n                             enc_output=enc_output,\n                             mask=(input_tokens!=0))\n    \n    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n\n    attention.append(dec_result.attention_weights)\n\n    new_tokens = self.sample(dec_result.logits, temperature)\n\n    # If a sequence produces an `end_token`, set it `done`\n    done = done | (new_tokens == self.end_token)\n    # Once a sequence is done it only produces 0-padding.\n    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n\n    # Collect the generated tokens\n    result_tokens.append(new_tokens)\n\n    if tf.executing_eagerly() and tf.reduce_all(done):\n      break\n\n  # Convert the list of generates token ids to a list of strings.\n  result_tokens = tf.concat(result_tokens, axis=-1)\n  result_text = self.tokens_to_text(result_tokens)\n\n  if return_attention:\n    attention_stack = tf.concat(attention, axis=1)\n    return {'text': result_text, 'attention': attention_stack}\n  else:\n    return {'text': result_text}\n","metadata":{"id":"ZmOvVrZmwAxg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Translator.translate = translate_unrolled","metadata":{"id":"JOmd8Y269MG3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TESTING\ninput_text = tf.constant([\n    'Waise really miss those days...', \n    'Yahi haal hai', \n])\n\nresult = translator.translate(\n    input_text = input_text)\n\nprint(result['text'][0].numpy().decode())\nprint(result['text'][1].numpy().decode())\nprint()","metadata":{"id":"hd2rgyHwVVrv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"72a81edc-d510-4038-fc8b-527a5b824127","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\ndef tf_translate(self, input_text):\n  return self.translate(input_text)\n\nTranslator.tf_translate = tf_translate","metadata":{"id":"_JhTZ5hOptO-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nresult = translator.tf_translate(\n    input_text = input_text)","metadata":{"id":"_NzrixLvVBjQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"469e8d6c-c011-43b1-ead8-0f442e9c602f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nresult = translator.tf_translate(\n    input_text = input_text)\n\nprint(result['text'][0].numpy().decode())\nprint(result['text'][1].numpy().decode())\nprint()","metadata":{"id":"USJdu00tVFbd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c40b1e8-a2a9-4ad1-9992-430dd580d8fb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title [Optional] Use a symbolic loop\ndef translate_symbolic(self,\n                       input_text,\n                       *,\n                       max_length=50,\n                       return_attention=True,\n                       temperature=1.0):\n  shape_checker = ShapeChecker()\n  shape_checker(input_text, ('batch',))\n\n  batch_size = tf.shape(input_text)[0]\n\n  # Encode the input\n  input_tokens = self.input_text_processor(input_text)\n  shape_checker(input_tokens, ('batch', 's'))\n\n  enc_output, enc_state = self.encoder(input_tokens)\n  shape_checker(enc_output, ('batch', 's', 'enc_units'))\n  shape_checker(enc_state, ('batch', 'enc_units'))\n\n  # Initialize the decoder\n  dec_state = enc_state\n  new_tokens = tf.fill([batch_size, 1], self.start_token)\n  shape_checker(new_tokens, ('batch', 't1'))\n\n  # Initialize the accumulators\n  result_tokens = tf.TensorArray(tf.int64, size=1, dynamic_size=True)\n  attention = tf.TensorArray(tf.float32, size=1, dynamic_size=True)\n  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n  shape_checker(done, ('batch', 't1'))\n\n  for t in tf.range(max_length):\n    dec_input = DecoderInput(\n        new_tokens=new_tokens, enc_output=enc_output, mask=(input_tokens != 0))\n\n    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n\n    shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n    attention = attention.write(t, dec_result.attention_weights)\n\n    new_tokens = self.sample(dec_result.logits, temperature)\n    shape_checker(dec_result.logits, ('batch', 't1', 'vocab'))\n    shape_checker(new_tokens, ('batch', 't1'))\n\n    # If a sequence produces an `end_token`, set it `done`\n    done = done | (new_tokens == self.end_token)\n    # Once a sequence is done it only produces 0-padding.\n    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n\n    # Collect the generated tokens\n    result_tokens = result_tokens.write(t, new_tokens)\n\n    if tf.reduce_all(done):\n      break\n\n  # Convert the list of generated token ids to a list of strings.\n  result_tokens = result_tokens.stack()\n  shape_checker(result_tokens, ('t', 'batch', 't0'))\n  result_tokens = tf.squeeze(result_tokens, -1)\n  result_tokens = tf.transpose(result_tokens, [1, 0])\n  shape_checker(result_tokens, ('batch', 't'))\n\n  result_text = self.tokens_to_text(result_tokens)\n  shape_checker(result_text, ('batch',))\n\n  if return_attention:\n    attention_stack = attention.stack()\n    shape_checker(attention_stack, ('t', 'batch', 't1', 's'))\n\n    attention_stack = tf.squeeze(attention_stack, 2)\n    shape_checker(attention_stack, ('t', 'batch', 's'))\n\n    attention_stack = tf.transpose(attention_stack, [1, 0, 2])\n    shape_checker(attention_stack, ('batch', 't', 's'))\n\n    return {'text': result_text, 'attention': attention_stack}\n  else:\n    return {'text': result_text}","metadata":{"id":"EbQpyYs13jF_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Translator.translate = translate_symbolic","metadata":{"id":"ngywxv1WYO_O","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The initial implementation used python lists to collect the outputs. This uses `tf.range` as the loop iterator, allowing `tf.autograph` to convert the loop. The biggest change in this implementation is the use of `tf.TensorArray` instead of python `list` to accumulate tensors. `tf.TensorArray` is required to collect a variable number of tensors in graph mode. ","metadata":{"id":"lItV7qjEGsYc"}},{"cell_type":"markdown","source":"With eager execution this implementation performs on par with the original:","metadata":{"id":"AJ_NznOgZTxC"}},{"cell_type":"code","source":"# RUN THIS\nresult = translator.translate(\n    input_text = input_text)\n\nprint(result['text'][0].numpy().decode())\nprint(result['text'][1].numpy().decode())\nprint()","metadata":{"id":"JRh66y-YYeBw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8992e4bf-e4c7-47cb-84a4-0465f2153d83","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But when you wrap it in a `tf.function` you'll notice two differences.","metadata":{"id":"l6B8W4_MZdX0"}},{"cell_type":"code","source":"@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\ndef tf_translate(self, input_text):\n  return self.translate(input_text)\n\nTranslator.tf_translate = tf_translate","metadata":{"id":"WX6EF8KtYh20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First: Graph creation is much faster (~10x), since it doesn't create `max_iterations` copies of the model.","metadata":{"id":"9S0kQ-bBZswZ"}},{"cell_type":"code","source":"%%time\nresult = translator.tf_translate(\n    input_text = input_text)","metadata":{"id":"Eq8d40RKYoJa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8bfbaaa-9b1c-4eaa-d08e-78b76749add4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Second: The compiled function is much faster on small inputs (5x on this example), because it can break out of the loop.","metadata":{"id":"2ABEwtKIZ6eE"}},{"cell_type":"code","source":"%%time\nresult = translator.tf_translate(\n    input_text = input_text)\n\nprint(result['text'][0].numpy().decode())\nprint(result['text'][1].numpy().decode())\nprint()","metadata":{"id":"d5VdCLxPYrpz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b0e36859-576d-4d40-c6df-efb0b3f7a4c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the process","metadata":{"id":"eo5sf4jZaO2l"}},{"cell_type":"markdown","source":"The attention weights returned by the `translate` method show where the model was \"looking\" when it generated each output token.\n\nSo the sum of the attention over the input should return all ones:","metadata":{"id":"FzZzC2cJacTv"}},{"cell_type":"code","source":"a = result['attention'][0]\n\nprint(np.sum(a, axis=-1))","metadata":{"id":"UEd2GljgqQ-0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"79eecf74-f06e-4d9a-ec44-5338c4df2c8c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is the attention distribution for the first output step of the first example. Note how the attention is now much more focused than it was for the untrained model:","metadata":{"id":"k_HWQHcI2_h5"}},{"cell_type":"code","source":"_ = plt.bar(range(len(a[0, :])), a[0, :])","metadata":{"id":"M8BHdqQujALu","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"31b6618c-07e0-4821-c953-efe35ddc95e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there is some rough alignment between the input and output words, you expect the attention to be focused near the diagonal:","metadata":{"id":"qB13OG472Z3V"}},{"cell_type":"code","source":"plt.imshow(np.array(a), vmin=0.0)","metadata":{"id":"xyeXuEYHd0kQ","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"8e85df2f-bfc4-43db-abd2-412001afb29e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is some code to make a better attention plot:","metadata":{"id":"mXECcNTn2mxN"}},{"cell_type":"code","source":"#@title Labeled attention plots\ndef plot_attention(attention, sentence, predicted_sentence):\n  sentence = tf_lower_and_split_punct(sentence).numpy().decode().split()\n  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n  fig = plt.figure(figsize=(10, 10))\n  ax = fig.add_subplot(1, 1, 1)\n\n  attention = attention[:len(predicted_sentence), :len(sentence)]\n\n  ax.matshow(attention, cmap='viridis', vmin=0.0)\n\n  fontdict = {'fontsize': 14}\n\n  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n\n  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n  ax.set_xlabel('Input text')\n  ax.set_ylabel('Output text')\n  plt.suptitle('Attention weights')","metadata":{"id":"s5hQWlbN3jGF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=0\nplot_attention(result['attention'][i], input_text[i], result['text'][i])","metadata":{"id":"rrGawQv2eiA4","colab":{"base_uri":"https://localhost:8080/","height":660},"outputId":"a8ce33b3-cfaf-49f9-c04f-2f6e89d90eeb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doublemetaphone('sabse')[0]+'*'+doublemetaphone('sabse'[::-1])[0]+'*'+'sabse'[:2]+'*'+'sabse'[len(j)-1:]+' '+doublemetaphone('best')[0]+'*'+doublemetaphone('best'[::-1])[0]+'*'+'best'[:2]+'*'+'best'[len(j)-1:]+' '+doublemetaphone('friend')[0]+'*'+doublemetaphone('friend'[::-1])[0]+'*'+'friend'[:2]+'*'+'friend'[len(j)-1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nthree_input_text = tf.constant([#'sabse best friend', \n                                #'That toh I know',\n                                #'She was bhunnoing the masalas jub phone ki ghuntee bugee',\n                                #'tum batao',\n                                #'kya karna hai',\n                                'SPS*ASPS*sa*e PST*TSP*be* FRNT*TNRF*fr*nd'\n])\n\nresult = translator.tf_translate(three_input_text)\nprint(result['text'])\nfor tr in result['text']:\n  print(tr.numpy().decode())\n\nprint()","metadata":{"id":"WrAM0FDomq3E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8641124a-e81a-4aea-ff61-51425a2e0b42","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result['text']","metadata":{"id":"-LjFp0AljOaZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f3de323-4809-4d52-8092-bac9d1e1f8fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nplot_attention(result['attention'][i], three_input_text[i], result['text'][i])","metadata":{"id":"v7QwIMrG-id2","colab":{"base_uri":"https://localhost:8080/","height":612},"outputId":"02b9f2a4-4ea0-4b45-a294-283b21e1cec9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 1\nplot_attention(result['attention'][i], three_input_text[i], result['text'][i])","metadata":{"id":"zYVoVf8P-lr-","colab":{"base_uri":"https://localhost:8080/","height":575},"outputId":"59fde2f6-58e3-4cfa-e9b1-f2bba1a872a4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 2\nplot_attention(result['attention'][i], three_input_text[i], result['text'][i])","metadata":{"id":"9sFvlZBk-me4","colab":{"base_uri":"https://localhost:8080/","height":621},"outputId":"7e25b713-c576-4c03-8614-c55bb3c7d83e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"long_input_text = tf.constant([inp[-1]])\n\nimport textwrap\nprint('Expected output:\\n', '\\n'.join(textwrap.wrap(targ[-1])))","metadata":{"id":"-FUHFLEvSMbG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ea7bcc6-e870-4959-dc40-dd0e6b1ff60a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = translator.tf_translate(long_input_text)\n\ni = 0\nplot_attention(result['attention'][i], long_input_text[i], result['text'][i])\n_ = plt.suptitle('Graph')","metadata":{"id":"lDa_8NaN_RUy","colab":{"base_uri":"https://localhost:8080/","height":612},"outputId":"e8e9580b-e815-465d-dc0b-e42875d3399c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.saved_model.save(translator, 'translator',\n                    signatures={'serving_default': translator.tf_translate})","metadata":{"id":"OyvxT5V0_X5B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ced85551-7dd8-48b7-cf12-b37055831235","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reloaded = tf.saved_model.load('translator')\nresult = reloaded.tf_translate(three_input_text)","metadata":{"id":"-I0j3i3ekOba","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nresult = reloaded.tf_translate(three_input_text)\n\nfor tr in result['text']:\n  print(tr.numpy().decode())\n\nprint()","metadata":{"id":"GXZF__FZXJCm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2473fa25-b3e1-460d-a647-76c1350f2c81","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!zip -r translator.zip translator","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XO-mhU6QbriO","outputId":"5003fd2c-734e-4688-8350-3823698bb2f3","trusted":true},"execution_count":null,"outputs":[]}]}